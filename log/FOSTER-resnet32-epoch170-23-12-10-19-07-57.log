{'data_root': '/root/autodl-tmp/cifar100', 'image_size': 32, 'pin_memory': False, 'augment': True, 'workers': 8, 'device_ids': 0, 'n_gpu': 1, 'seed': 1993, 'deterministic': True, 'epoch': 170, 'batch_size': 128, 'val_per_epoch': 10, 'optimzer': {'name': 'SGD', 'kwargs': {'lr': 0.1}}, 'lr_scheduler': {'name': 'CosineAnnealingLR', 'kwargs': {'T_max': 170}}, 'warmup': 0, 'includes': ['headers/device.yaml'], 'save_path': './', 'init_cls_num': 50, 'inc_cls_num': 10, 'total_cls_num': 100, 'task_num': 6, 'init_epoch': 0, 'init_lr': 0.1, 'init_weight_decay': 0.0005, 'backbone': {'name': 'resnet32', 'kwargs': None}, 'classifier': {'name': 'FOSTER', 'kwargs': {'num_class': 100, 'feat_dim': 64, 'beta1': 0.94, 'beta2': 0.97, 'is_teacher_wa': False, 'is_student_wa': False, 'lambda_okd': 1, 'wa_value': 1, 'oofc': 'az', 'convnet_type': 'resnet32', 'T': 2, 'fixed_memory': True, 'memory_per_class': 20, 'lr': 0.1, 'compression_epochs': 130}}, 'num_workers': 8, 'buffer': {'name': 'LinearBuffer', 'kwargs': {'buffer_size': 500, 'batch_size': 32, 'strategy': 'foster'}}, 'optimizer': {'name': 'SGD', 'kwargs': {'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0005}}, 'rank': 0}
FOSTER(
  (backbone): CifarResNet(
    (conv_1_3x3): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (stage_1): Sequential(
      (0): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): ResNetBasicblock(
        (conv_a): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (stage_2): Sequential(
      (0): ResNetBasicblock(
        (conv_a): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): DownsampleA(
          (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
        )
      )
      (1): ResNetBasicblock(
        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): ResNetBasicblock(
        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): ResNetBasicblock(
        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): ResNetBasicblock(
        (conv_a): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (stage_3): Sequential(
      (0): ResNetBasicblock(
        (conv_a): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): DownsampleA(
          (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
        )
      )
      (1): ResNetBasicblock(
        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): ResNetBasicblock(
        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): ResNetBasicblock(
        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): ResNetBasicblock(
        (conv_a): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
    (fc): Linear(in_features=64, out_features=10, bias=True)
  )
  (classifier): Linear(in_features=64, out_features=100, bias=True)
  (loss_fn): CrossEntropyLoss()
  (_network): FOSTERNet(
    (convnets): ModuleList()
  )
)
Trainable params in the model: 0
================Task 0 Start!================
Trainable params in the model: 0
Learning on 0-50
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
)
================Task 0 Training!================
The training samples number: 25000
Construct examplars for class 0
Construct examplars for class 1
Construct examplars for class 2
Construct examplars for class 3
Construct examplars for class 4
Construct examplars for class 5
Construct examplars for class 6
Construct examplars for class 7
Construct examplars for class 8
Construct examplars for class 9
Construct examplars for class 10
Construct examplars for class 11
Construct examplars for class 12
Construct examplars for class 13
Construct examplars for class 14
Construct examplars for class 15
Construct examplars for class 16
Construct examplars for class 17
Construct examplars for class 18
Construct examplars for class 19
Construct examplars for class 20
Construct examplars for class 21
Construct examplars for class 22
Construct examplars for class 23
Construct examplars for class 24
Construct examplars for class 25
Construct examplars for class 26
Construct examplars for class 27
Construct examplars for class 28
Construct examplars for class 29
Construct examplars for class 30
Construct examplars for class 31
Construct examplars for class 32
Construct examplars for class 33
Construct examplars for class 34
Construct examplars for class 35
Construct examplars for class 36
Construct examplars for class 37
Construct examplars for class 38
Construct examplars for class 39
Construct examplars for class 40
Construct examplars for class 41
Construct examplars for class 42
Construct examplars for class 43
Construct examplars for class 44
Construct examplars for class 45
Construct examplars for class 46
Construct examplars for class 47
Construct examplars for class 48
Construct examplars for class 49
================Task 1 Start!================
Trainable params in the model: 470654
Learning on 50-60
per cls weights : [1.05080764 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764
 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764
 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764
 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764
 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764
 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764
 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764
 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764 1.05080764
 1.05080764 1.05080764 0.74596179 0.74596179 0.74596179 0.74596179
 0.74596179 0.74596179 0.74596179 0.74596179 0.74596179 0.74596179]
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 0.0005
)
================Task 1 Training!================
The training samples number: 6000
learning rate: [0.1]
================ Train on the train set ================
Epoch [0/170] |	Loss: 12.689 	Average Acc: 10.377 
learning rate: [0.09999146252290264]
================ Train on the train set ================
Epoch [1/170] |	Loss: 11.191 	Average Acc: 19.464 
learning rate: [0.09996585300715116]
================ Train on the train set ================
Epoch [2/170] |	Loss: 9.089 	Average Acc: 26.460 
learning rate: [0.09992318019837171]
================ Train on the train set ================
Epoch [3/170] |	Loss: 8.353 	Average Acc: 31.420 
learning rate: [0.09986345866928942]
================ Train on the train set ================
Epoch [4/170] |	Loss: 8.196 	Average Acc: 33.831 
learning rate: [0.09978670881475173]
================ Train on the train set ================
Epoch [5/170] |	Loss: 8.115 	Average Acc: 36.752 
learning rate: [0.0996929568447637]
================ Train on the train set ================
Epoch [6/170] |	Loss: 9.280 	Average Acc: 36.480 
learning rate: [0.09958223477553715]
================ Train on the train set ================
Epoch [7/170] |	Loss: 9.829 	Average Acc: 38.604 
learning rate: [0.09945458041855731]
================ Train on the train set ================
Epoch [8/170] |	Loss: 7.900 	Average Acc: 40.150 
learning rate: [0.09931003736767013]
================ Train on the train set ================
